#Below sample yaml is used to schedule pods on 2 A100 GPUs

apiVersion: v1
kind: Pod
metadata:
 name: a100-codet5-small-low-resource-fine-tune-after-pretrain-tfix-30-10
 namespace: sfr-ns-weishi-wang
spec:
  restartPolicy: OnFailure
  volumes:
    - name: sfr-home-pv-weishi-wang
      persistentVolumeClaim:
        claimName: sfr-home-pvc-weishi-wang
    - name: sfr-share-pv-weishi-wang
      persistentVolumeClaim:
        claimName: sfr-share-pvc-weishi-wang
    - name: dshm
      emptyDir:
        medium: Memory
  containers:
    - name: weishi-env-a100
      image: "gcr.io/salesforce-research-internal/weishi-a100-env"
      command: ["/bin/bash", "-c", "cd /export/home/share/repair_CodeT5/sh && export PATH=/export/home/anaconda3/bin:$PATH && source activate a100 && python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_30_shot_13_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_30_shot_21_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_30_shot_42_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_30_shot_87_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_10_shot_100_seed  --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_10_shot_13_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_10_shot_21_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_10_shot_42_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin &&
python run_exp.py --model_tag codet5_small --tag_suffix finetune --task tfix_low_resource_10_shot_87_seed   --load_model_dir /export/home/share/repair_CodeT5/pretrained_models/codet5_small/pytorch_model.bin"]
      resources:
        limits:
          nvidia.com/gpu: 1
          cpu: "11"
          memory: 75G
      volumeMounts:
        - name: sfr-home-pv-weishi-wang
          mountPath: "/export/home"
        - name: sfr-share-pv-weishi-wang
          mountPath: "/export/share"
        - name: dshm
          mountPath: "/dev/shm"
  nodeSelector:
    cloud.google.com/gke-accelerator: nvidia-tesla-a100
  tolerations:
  - key: "gpu_num"
    operator: "Equal"
    value: "2"
    effect: "NoSchedule"

